[training]
    num_epochs = 100
    optimizer = "ADAM"
    optimizer_params = {lr = 0.01}
    loss = "logitcrossentropy"
    loss_params = {dims = 1, agg = "mean"}
    is_supervised = true
    batch_size = 32

[architecture]
    name = "mlp_classifier_test"
    input_size = [50]
    num_classes = 10

layers = [
    {f = "dense", out=100, sigma="identity"},
    {f = "dense", out=10, sigma="relu"}
]